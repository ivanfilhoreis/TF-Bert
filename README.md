# bertVectorizer

Convert a collection of raw documents to a matrix extracted from BERT resources. 

This implementation produces a non-sparse representation of the text's resource count.

# 1. Installation

Installation and use can be done as:

```
!pip install git+https://github.com/ivanfilhoreis/bertVectorizer.git -q
!pip install -U sentence-transformers -q
```
# 2. Usage

```
from bertVectorizer import bertVectorizer
import pandas as pd

dic = {
       'text': ['Machine learning is the study of computer algorithms that can improve automatically through experience and by the use of data',
                'Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features',
                'Support-vector machines also known as support-vector networks are a set of related supervised learning methods used for classification and regression',
                'Decision tree learning uses a decision tree as a predictive model to go from observations about an item',
                'Performing machine learning involves creating a model which is trained on some training data and then can process additional data to make predictions']}
            
df = pd.DataFrame(dic)

```

You can set keyphrase_ngram_range to set the length of the resulting keywords/keyphrases:


```python
>>> vectorizer = bertVectorizer()
>>> matrix = vectorizer.fit_transform(df)

index	additional	algorithm	also	analysis	associate	automatically	classification	computer	create	datum	decision	encompass	estimate	experience	feature	go	improve	input	involve	item
0	0.07413104176521301	0.5081286430358887	0.010698435828089714	0.3017493784427643	0.053499266505241394	0.1425294578075409	0.14584165811538696	0.3724671006202698	0.10567314922809601	0.16573014855384827	0.10773348063230515	0.20345740020275116	0.16754911839962006	0.1826934516429901	0.12216996401548386	-0.0536232627928257	0.2904198169708252	0.14859539270401	0.07203037291765213	0.01739698089659214
1	0.2506425976753235	0.4057082533836365	0.10462776571512222	0.524585485458374	0.13170559704303741	0.06600809097290039	0.2874671518802643	0.12485230714082718	0.09655455499887466	0.3436737060546875	0.22856125235557556	0.32272475957870483	0.3596895933151245	0.15337097644805908	0.18730756640434265	-0.026742706075310707	0.16168080270290375	0.3101257383823395	0.16528168320655823	0.1304643750190735
2	0.23797494173049927	0.5051600337028503	0.15961384773254395	0.2816728949546814	0.12256412208080292	0.1282006800174713	0.2704851031303406	0.3069169521331787	0.16112294793128967	0.2752317786216736	0.09160491079092026	0.29509684443473816	0.18099141120910645	0.15866529941558838	0.25692737102508545	0.02902083285152912	0.22068515419960022	0.21484746038913727	0.1691347360610962	0.12000107765197754
3	0.11922654509544373	0.40491652488708496	0.004098055884242058	0.32078295946121216	0.17633923888206482	0.12564511597156525	0.22855809330940247	0.1265382468700409	0.13052022457122803	0.2828735411167145	0.40775802731513977	0.18678534030914307	0.3296685516834259	0.176266148686409	0.14445944130420685	0.05844338610768318	0.1551036238670349	0.17400670051574707	0.17112237215042114	0.14135026931762695
4	0.1427718847990036	0.45732957124710083	0.040414679795503616	0.30193620920181274	0.0918176919221878	0.1633155792951584	0.21077275276184082	0.2584514021873474	0.21003921329975128	0.2770029902458191	0.13138265907764435	0.2243666648864746	0.3032137155532837	0.22181198000907898	0.1391320824623108	-0.07996199280023575	0.169644296169281	0.1938152015209198	0.10773163288831711	0.07779743522405624

```


